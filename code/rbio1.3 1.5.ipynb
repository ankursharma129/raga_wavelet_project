{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008ed29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "import threading\n",
    "import python_speech_features\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import math\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import pickle\n",
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.layers import Dropout\n",
    "from os.path import isfile, join\n",
    "from keras.layers import Flatten, Conv1D, Input, MaxPooling1D, Conv2D, MaxPooling2D, BatchNormalization, Reshape\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir\n",
    "import pywt\n",
    "from pywt import dwt, wavedec\n",
    "from os.path import isfile, join\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, df,\n",
    "                 batch_size, validation,\n",
    "                 shuffle=True):\n",
    "\n",
    "        self.df = df.copy()\n",
    "        if validation:\n",
    "            self.df = self.df[25000:]\n",
    "        else:\n",
    "            self.df = self.df[:25000]\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "        self.n = len(self.df)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __get_input(self, path):\n",
    "    \n",
    "        objects = []\n",
    "        with (open(path, \"rb\")) as openfile:\n",
    "            while True:\n",
    "                try:\n",
    "                    objects.append(pickle.load(openfile))\n",
    "                except EOFError:\n",
    "                    break\n",
    "        return objects[0][\"audio\"]\n",
    "\n",
    "    \n",
    "    def __get_output(self, tag):\n",
    "        return lab[tag]\n",
    "    \n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        files = batches[\"file\"]\n",
    "        tag = batches[\"tag\"]\n",
    "\n",
    "        X_batch = np.asarray([self.__get_input(x) for x in files])\n",
    "\n",
    "        y_batch = np.asarray([self.__get_output(y) for y in tag])\n",
    "\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batches = self.df[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X, y = self.__get_data(batches)        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def445c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('dataGenbior1.5level7.csv')\n",
    "dat = []\n",
    "files = dft[\"file\"]\n",
    "for i in files:\n",
    "    if i.split(\"/\")[-2] not in dat:\n",
    "        dat.append(i.split(\"/\")[-2])\n",
    "\n",
    "lab = {}\n",
    "\n",
    "for i in range(84):\n",
    "    tag = dat[i]\n",
    "    y_label = np.zeros((84))\n",
    "    y_label[i] = 1\n",
    "    lab[tag] = y_label\n",
    "    \n",
    "less = 0\n",
    "good = 0\n",
    "window_size = 2048\n",
    "hop_size =256\n",
    "allLabels = []\n",
    "sample_rate = 44100\n",
    "\n",
    "def AttRNNSpeechModel(rnn_func=L.LSTM):\n",
    "    inputs = Input(shape=(1, 20, 216))\n",
    "    x = L.Conv2D(128, (5, 1), activation='relu', padding='same')(inputs)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(64, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(32, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(16, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(8, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "\n",
    "    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "    x = L.Bidirectional(rnn_func(64, return_sequences=True)\n",
    "                        )(x)\n",
    "    x = L.Bidirectional(rnn_func(32, return_sequences=True)\n",
    "                        )(x)\n",
    "\n",
    "    xFirst = L.Lambda(lambda q: q[:, -1])(x)\n",
    "    query = L.Dense(64)(xFirst)\n",
    "\n",
    "    # dot product attention\n",
    "    attScores = L.Dot(axes=[1, 2])([query, x])\n",
    "    attScores = L.Softmax(name='attSoftmax')(attScores)\n",
    "\n",
    "    # rescale sequence\n",
    "    attVector = L.Dot(axes=[1, 1])([attScores, x])\n",
    "\n",
    "    x = L.Dense(64, activation='relu')(attVector)\n",
    "    x = L.Dense(32, activation='relu')(attVector)\n",
    "    x = L.Dense(16)(x)\n",
    "\n",
    "    output = L.Dense(84, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = AttRNNSpeechModel()#, rnn_func=L.LSTM)\n",
    "\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.00001) \n",
    "dft = shuffle(dft)\n",
    "training_generator = CustomDataGen(dft, 32, False)\n",
    "validation_generator = CustomDataGen(dft, 32, True)\n",
    "mc = ModelCheckpoint('best_modelstft.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "history=model.fit_generator(generator=training_generator, validation_data = validation_generator, epochs=50, callbacks=[mc,es], use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f118f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('dataGendb4level7.csv')\n",
    "dat = []\n",
    "files = dft[\"file\"]\n",
    "for i in files:\n",
    "    if i.split(\"/\")[-2] not in dat:\n",
    "        dat.append(i.split(\"/\")[-2])\n",
    "\n",
    "lab = {}\n",
    "\n",
    "for i in range(84):\n",
    "    tag = dat[i]\n",
    "    y_label = np.zeros((84))\n",
    "    y_label[i] = 1\n",
    "    lab[tag] = y_label\n",
    "    \n",
    "less = 0\n",
    "good = 0\n",
    "window_size = 2048\n",
    "hop_size =256\n",
    "allLabels = []\n",
    "sample_rate = 44100\n",
    "\n",
    "def AttRNNSpeechModel(rnn_func=L.LSTM):\n",
    "    inputs = Input(shape=(9, 20, 216))\n",
    "    x = L.Conv2D(128, (5, 1), activation='relu', padding='same')(inputs)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(64, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(32, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(16, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(8, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(1, (5, 1), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "\n",
    "    x = L.Lambda(lambda q: K.squeeze(q, -1), name='squeeze_last_dim')(x)\n",
    "\n",
    "    x = L.Bidirectional(rnn_func(64, return_sequences=True)\n",
    "                        )(x)\n",
    "    x = L.Bidirectional(rnn_func(32, return_sequences=True)\n",
    "                        )(x)\n",
    "\n",
    "    xFirst = L.Lambda(lambda q: q[:, -1])(x)\n",
    "    query = L.Dense(64)(xFirst)\n",
    "\n",
    "    # dot product attention\n",
    "    attScores = L.Dot(axes=[1, 2])([query, x])\n",
    "    attScores = L.Softmax(name='attSoftmax')(attScores)\n",
    "\n",
    "    # rescale sequence\n",
    "    attVector = L.Dot(axes=[1, 1])([attScores, x])\n",
    "\n",
    "    x = L.Dense(64, activation='relu')(attVector)\n",
    "    x = L.Dense(32, activation='relu')(attVector)\n",
    "    x = L.Dense(16)(x)\n",
    "\n",
    "    output = L.Dense(84, activation='softmax', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = AttRNNSpeechModel()#, rnn_func=L.LSTM)\n",
    "\n",
    "model.compile(optimizer='adam', loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.00001) \n",
    "dft = shuffle(dft)\n",
    "training_generator = CustomDataGen(dft, 32, False)\n",
    "validation_generator = CustomDataGen(dft, 32, True)\n",
    "mc = ModelCheckpoint('best_modeldb4level7.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "history=model.fit_generator(generator=training_generator, validation_data = validation_generator, epochs=50, callbacks=[mc,es], use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de85baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "unique = 0\n",
    "d = []\n",
    "file = \"./saraga1.5_hindustani/Raag Shree by Deborshee Bhattacharya/Raag Shree/431bior1.5level7.pickle\"\n",
    "\n",
    "objects = []\n",
    "tag = file.split(\"/\")[-2]\n",
    "d.append(tag)\n",
    "with (open(file, \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653de6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(np.reshape(objects[0][\"audio\"][0],(1,20,216)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a241bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
