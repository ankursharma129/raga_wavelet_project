{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc3b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "import threading\n",
    "import python_speech_features\n",
    "from scipy.io import wavfile\n",
    "import scipy.fftpack as fft\n",
    "from scipy.signal import get_window\n",
    "import IPython.display as ipd\n",
    "import math\n",
    "%matplotlib inline\n",
    "import librosa\n",
    "import pickle\n",
    "import pywt\n",
    "from pywt import dwt, wavedec\n",
    "from os import listdir\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761e2d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainDir = \"free-spoken-digit-dataset-master/recordings/\"\n",
    "# testDir = \"test/\"\n",
    "trainFiles = [f for f in listdir(trainDir) if isfile(join(trainDir, f))]\n",
    "# testFiles = [f for f in listdir(testDir) if isfile(join(testDir, f))]\n",
    "# print(len(trainFiles))\n",
    "# print(len(testFiles))\n",
    "# metaFile = \"FSDKaggle2018.meta/train_post_competition.csv\"\n",
    "# meta = pd.read_csv(metaFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b14bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnMelCoeff(signal, sr):\n",
    "    return librosa.feature.mfcc(signal, sr)\n",
    "\n",
    "def windowHann(signal, fr, windowSize):\n",
    "    window = get_window(\"hann\", windowSize)\n",
    "    windowed = signal * window\n",
    "    return windowed\n",
    "\n",
    "def padSignal(signal, sr, windowSize, hopSize):\n",
    "    signalLength = len(signal)\n",
    "    numZeros = windowSize - (signalLength - math.floor(signalLength/hopSize)*hopSize);\n",
    "    return np.concatenate((signal, np.zeros(numZeros)), axis=None)\n",
    "\n",
    "# def process(signal, sr, windowSize, hopSize):\n",
    "#     origLength = len(signal)\n",
    "#     signal = padSignal(signal, sr, windowSize, hopSize)\n",
    "#     mfccArray = []\n",
    "#     for i in range(0, origLength, hopSize):\n",
    "#         toProcess = windowHann(signal[i: i+windowSize], sr, windowSize)\n",
    "#         tempArr = []\n",
    "#         a, d5, d4, d3, d2, d1 = wavedec(toProcess, 'db32', level=levels)\n",
    "#         mfccs5 = python_speech_features.mfcc(d5, sr, winlen=(len(d5)/sr), nfft = len(d5), winstep=(len(d5)/sr), numcep=1)\n",
    "#         mfccs4 = python_speech_features.mfcc(d4, sr, winlen=(len(d4)/sr), nfft = len(d4), winstep=(len(d4)/sr), numcep=1)\n",
    "#         mfccs3 = python_speech_features.mfcc(d3, sr, winlen=(len(d3)/sr), nfft = len(d3), winstep=(len(d3)/sr), numcep=2)\n",
    "#         mfccs2 = python_speech_features.mfcc(d2, sr, winlen=(len(d2)/sr), nfft = len(d2), winstep=(len(d2)/sr), numcep=3)\n",
    "#         mfccs1 = python_speech_features.mfcc(d1, sr, winlen=(len(d1)/sr), nfft = len(d1), winstep=(len(d1)/sr), numcep=5)\n",
    "#         mfccsa = python_speech_features.mfcc(a, sr, winlen=(len(a)/sr), nfft = len(a), winstep=(len(a)/sr), numcep=1)\n",
    "#         tempArr.append(mfccs5[0])\n",
    "#         tempArr.append(mfccs4[0])\n",
    "#         tempArr.append(mfccs3[0])\n",
    "#         tempArr.append(mfccs2[0])\n",
    "#         tempArr.append(mfccs1[0])\n",
    "#         tempArr.append(mfccsa[0])\n",
    "#         mfccArray.append([p for d in tempArr for p in d])\n",
    "\n",
    "#     return mfccArray\n",
    "\n",
    "windowSize = 1235\n",
    "hopSize = 1102\n",
    "levels = 5\n",
    "\n",
    "fName = os.path.join(trainDir, trainFiles[1])\n",
    "signal, sr = librosa.load(fName)\n",
    "mfccArray = process(signal, sr, windowSize, hopSize)\n",
    "\n",
    "\n",
    "with open('dumpfilewaveletsMNIST.pickle', 'wb') as handle:\n",
    "    for i in trainFiles:\n",
    "        fName = os.path.join(trainDir, i)\n",
    "        signal, sr = librosa.load(fName)\n",
    "        mfccArray = process(signal, sr, windowSize, hopSize)\n",
    "        a = {i: mfccArray}\n",
    "        pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(\"Done with: \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0786d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "levels = [3, 4, 5, 6]\n",
    "wavelets = ['bior2.4']\n",
    "windowSize = 512\n",
    "hopSize = 128\n",
    "\n",
    "def windowHann(signal, fr, windowSize):\n",
    "    window = get_window(\"hann\", windowSize)\n",
    "    windowed = signal * window\n",
    "    return windowed\n",
    "\n",
    "def padSignal(signal, sr, windowSize, hopSize):\n",
    "    signalLength = len(signal)\n",
    "    numZeros = windowSize - (signalLength - math.floor(signalLength/hopSize)*hopSize);\n",
    "    return np.concatenate((signal, np.zeros(numZeros)), axis=None)\n",
    "\n",
    "def processWaveletMFCCs(signal, sr, windowSize, hopSize, lv, wavelet):\n",
    "    origLength = len(signal)\n",
    "    signal = padSignal(signal, sr, windowSize, hopSize)\n",
    "    mfccArray = np.empty((math.ceil(origLength/hopSize), lv+1, 20))\n",
    "    block = 0\n",
    "    for i in range(0, origLength, hopSize):\n",
    "        toProcess = windowHann(signal[i: i+windowSize], sr, windowSize)\n",
    "        dec = wavedec(toProcess, wavelet, level=lv)\n",
    "        for j in range(len(dec)):\n",
    "            mfccArray[block, j, :] = python_speech_features.mfcc(dec[j], sr, winlen=(len(dec[j])/sr), nfft = len(dec[j]), winstep=(len(dec[j])/sr), numcep=20)[0]\n",
    "        block+=1\n",
    "    return mfccArray\n",
    "\n",
    "# testName = trainFiles[2]\n",
    "# fName = os.path.join(trainDir, testName)\n",
    "# signal, sr = librosa.load(fName)\n",
    "# print(len(signal))\n",
    "# mfccArray = processWaveletMFCCs(signal, sr, windowSize, hopSize, levels[0], wavelets[0])\n",
    "# print(np.shape(mfccArray))\n",
    "\n",
    "\n",
    "for wavelet in wavelets:\n",
    "    for lv in levels:\n",
    "        fileName = \"MNIST_\"+(wavelet).replace('.','') + \"_\"+str(lv)+\".pickle\"\n",
    "        with open(fileName, 'wb') as handle:\n",
    "            for i in trainFiles:\n",
    "                fName = os.path.join(trainDir, i)\n",
    "                signal, sr = librosa.load(fName)\n",
    "                mfccArray = processWaveletMFCCs(signal, sr, windowSize, hopSize, lv, wavelet)\n",
    "                a = {i: mfccArray}\n",
    "                pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0eb3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with (open(\"dumpfilewaveletsMNIST.pickle\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afe9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "pywt.wavelist('bior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad476d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44271/271276128.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filepath\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "lab = {}\n",
    "\n",
    "for i in range(10):\n",
    "    tag = df[\"filepath\"][i].split(\"/\")[1]\n",
    "    y_label = np.zeros((10))\n",
    "    y_label[i] = 1\n",
    "    lab[tag] = y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c366dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
